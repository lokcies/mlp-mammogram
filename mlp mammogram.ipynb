{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "mammogram = pd.read_csv('mammogram_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammogram.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "# In this dataset, missing values can be observed as -100000\n",
    "# Since our program can't really detect -100000 as a missing value as it might be read as a normal value, we are marking them\n",
    "# with 'NaN' value using numpy.replace\n",
    "mammogram[['BI_RADS_assessment', 'age', 'shape', 'margin', 'density', 'severity']] = \\\n",
    "    mammogram[['BI_RADS_assessment', 'age', 'shape', 'margin', 'density', 'severity']].replace(-100000, np.nan)\n",
    "# Hence, we now are able to check how many missing values are there for each attribute\n",
    "print(mammogram.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe dataset\n",
    "mammogram.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our program should now be able to replace those missing values, in this case we are\n",
    "# replacing it with mean values for each column/attribute\n",
    "mammogram.fillna(mammogram.mean(), inplace=True)\n",
    "# Check missing values again just to be sure\n",
    "print(mammogram.isnull().sum())\n",
    "# Observe dataset\n",
    "mammogram.head(10)\n",
    "#print(mammogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dalam semua data tu, kita check berapa banyak instances bagi setiap class\n",
    "# How many instances are there for each class?\n",
    "# 0-Benign, 2-Malignant\n",
    "mammogram['severity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph plot\n",
    "sns.countplot(mammogram['severity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting features variable and target variable\n",
    "# X -> features that we are working with\n",
    "# y -> target, in this case is severity\n",
    "X = mammogram.drop('severity', axis=1)\n",
    "y = mammogram['severity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing set\n",
    "# Ratio 66% / 33%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.66)\n",
    "# Observe how many instances for each variable\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In testing set, observe number of instances for each class\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph plot\n",
    "sns.countplot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe 10 samples of training set\n",
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization using Min-Max normalization\n",
    "# Why do we perform normalization after splitting the data?\n",
    "# -> To avoid data leakage, which means that the created model learns something other than the training set.\n",
    "# -> This allows the model to learn something it would not learn, and in turn invalidate the accuracy and performance of the model\n",
    "# Can also be said as: \n",
    "# -> The test set is supposed to be a fresh unseen data, and should not be modified at the training stage;\n",
    "# -> Doing so would cause potential bias in evaluating the performance\n",
    "normalization = MinMaxScaler()\n",
    "X_train = normalization.fit_transform(X_train)\n",
    "X_test = normalization.transform(X_test)\n",
    "\n",
    "# View first 10 instances of normalized data\n",
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "# 1st case\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=[4], activation='logistic', learning_rate='constant', learning_rate_init=0.8, max_iter=30, solver='sgd', verbose=False, random_state=1)\n",
    "# 2nd case\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=[4], activation='logistic', learning_rate='constant', learning_rate_init=0.8, max_iter=50, solver='sgd', verbose=False, random_state=1)\n",
    "# 3rd case\n",
    "mlp = MLPClassifier(hidden_layer_sizes=[4], activation='logistic', learning_rate='constant', learning_rate_init=0.50, max_iter=100, \\\n",
    "                    solver='sgd',verbose=True, random_state=1, momentum=0.92)\n",
    "# 2nd case w/ momentum\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=4, activation='logistic', learning_rate='constant', learning_rate_init=0.02, max_iter=1000, verbose=False, solver='sgd', momentum=0.25)\n",
    "# 3rd case w/ adaptive learning rate\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=5, activation='logistic', learning_rate='adaptive', learning_rate_init=0.02, max_iter=1000)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "predict_mlp = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tengok mse, accuracy & confusion matrix of model \n",
    "# Using sklearn classification_report and confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "mse = mean_squared_error(y_test, predict_mlp, squared=True)\n",
    "\n",
    "print(\"\\nMean Squared Error (MSE): \", mse, \"\\n\")\n",
    "#print(\"\\t===================================================\")\n",
    "#print(classification_report(y_test, predict_mlp))\n",
    "#print(\"\\t===================================================\")\n",
    "print(confusion_matrix(y_test, predict_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plot_confusion_matrix(mlp, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, predict_mlp)\n",
    "print(\"Model accuracy: \", accuracy, \"-> \", round(accuracy*100, 2), \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
